<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Wandering but not lost]]></title><description><![CDATA[A blog about my wanderings in technology and life]]></description><link>https://sohaibtariq.github.io</link><generator>RSS for Node</generator><lastBuildDate>Mon, 19 Aug 2019 11:47:01 GMT</lastBuildDate><item><title><![CDATA[Exponential backoff for AWS Lambda]]></title><description><![CDATA[I recently set up a Lambda function that reads data from an SQS Queue 
and makes an API call to one of our microservices. 
Naturally, thisâ€¦]]></description><link>https://sohaibtariq.github.io/exponential-backoff/</link><guid isPermaLink="false">https://sohaibtariq.github.io/exponential-backoff/</guid><pubDate>Mon, 19 Aug 2019 22:12:03 GMT</pubDate><content:encoded>&lt;p&gt;I recently set up a Lambda function that reads data from an SQS Queue
and makes an API call to one of our microservices.
Naturally, this calls for an error handling mechanism, considering that the microservice
could be down or unresponsive.&lt;/p&gt;
&lt;p&gt;AWS Lambda provides its own retry mechanism where a message is picked up from the queue by the Lambda
consumer and becomes invisible to other consumers for a specific duration called the &lt;em&gt;visibility timeout&lt;/em&gt;.
If the consumer completes execution successfully, it automatically deletes the message from the queue.
In case of unsuccesful execution (such as a Runtime Exception), the &lt;em&gt;approximate receive count&lt;/em&gt;
of the message is incremented and it becomes available to other consumers after the &lt;em&gt;visibility timeout&lt;/em&gt; passes.
The number of times a message can be re-read from the queue
before it is finally sent to a Dead Letter Queue(DLQ) is configured in the Redrive policy of the
SQS Queue and is tracked via the &lt;em&gt;approximate receive count&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;This retry mechanism was not exactly what I had in mind for our use case. I was thinking along the
lines of a backoff strategy that keeps retrying the API call with exponentially increasing wait time;
finally sending the message to a DLQ after a set number of retries. This would give us ample time to
fix any issues with our miscroservice and prevent it from being bombarded with failing API calls. &lt;/p&gt;
&lt;p&gt;This is what I ended up with: &lt;/p&gt;
&lt;p&gt;First, a very basic Java function to calculate the exponential wait time, given the number of
retries &lt;strong&gt;recvCount&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;        int randomInt = rand.nextInt(60);
        Long result = new Double(Math.pow(2, recvCount)).longValue() + 30 +randomInt;  //adding jitter to new random visibility timeout&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice the addition of &lt;strong&gt;randomInt&lt;/strong&gt;. That is &apos;jitter&apos;. A bit of randomness. I read about it in some
&lt;a href=&quot;https://cloud.google.com/storage/docs/exponential-backoff&quot;&gt;documentation&lt;/a&gt; by Google Cloud and included
it as a good practice.&lt;/p&gt;
&lt;p&gt;Next up, set the visibility timeout of the message to the value that we just calculated above. The maximum value allowed by AWS is 43200 seconds
or 12 hours. &lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;  sqs.changeMessageVisibility(queueUrl, msg.getReceiptHandle(), newVisibilityTimeout.intValue());&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, we check the response to our API call. If it is a 400 or 500 series response, we throw a Runtime Exception and change the visibility timeout of the
message. This is
the easiest way I could come up with to signal unsuccessful execution of the Lambda function. Plus, we can only throw unchecked exceptions
in our handler method.&lt;/p&gt;
&lt;div class=&quot;gatsby-highlight&quot; data-language=&quot;text&quot;&gt;&lt;pre class=&quot;language-text&quot;&gt;&lt;code class=&quot;language-text&quot;&gt;...
// api call
...  
 if (response.getStatusLine().getStatusCode() &amp;gt;= 400){
                            new ExponentialBackoff().setVisibilityTimeout(msg);
                            throw new RuntimeException(&amp;quot;Request to server failed&amp;quot;);
                        }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;ExponentialBackoff is my utility class where the code that calculates and sets the visibility timeout lives. It also has some other
utility functions that are not essential for this demonstration.&lt;/p&gt;
&lt;p&gt;There you have it; A bare bones exponential backoff implementation for AWS Lambda. &lt;/p&gt;</content:encoded></item></channel></rss>